{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Convolutional Neuran Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional layer\n",
    "Convolutional Neural Network (CNN) is a special type of feedforward neural network originally\n",
    "employed in the field of computer vision. Its design is inspired by the human visual cortex, a visual\n",
    "mechanism in animal brain. The visual cortex contains a lot of cells that are responsible for detecting\n",
    "light in small and overlapping sub-regions of the visual fields, which are called receptive fields. These\n",
    "cells act as local filters over the input space. CNN consists of multiple convolutional layers, each of\n",
    "which performs the function that is processed by the cells in the visual cortex.\n",
    "\n",
    "A neuron’s weights can be represented as a small image the size of the receptive field.\n",
    "    1. • filters is the set of filters to apply (also a 4D tensor, as explained earlier).\n",
    "    2. • strides is a four-element 1D array, where the two central elements are the verti‐\n",
    "    cal and horizontal strides (s h and s w ). The first and last elements must currently\n",
    "    be equal to 1. They may one day be used to specify a batch stride (to skip some\n",
    "    instances) and a channel stride (to skip some of the previous layer’s feature maps\n",
    "    or channels).\n",
    "    3. • padding must be either \"VALID\" or \"SAME\" :\n",
    "        — If set to \"VALID\" , the convolutional layer does not use zero padding, and may\n",
    "    ignore some rows and columns at the bottom and right of the input image,\n",
    "    depending on the stride, as shown in Figure 13-7 (for simplicity, only the hor‐\n",
    "    izontal dimension is shown here, but of course the same logic applies to the\n",
    "    vertical dimension).\n",
    "        — If set to \"SAME\" , the convolutional layer uses zero padding if necessary. In this\n",
    "    case, the number of output neurons is equal to the number of input neurons\n",
    "    divided by the stride, rounded up (in this example, ceil (13 / 5) = 3). Then\n",
    "    zeros are added as evenly as possible around the inputs.\n",
    "## Pooling Layer\n",
    "Their goal is to subsample (i.e., shrink) the input image in order to\n",
    "reduce the computational load, the memory usage, and the number of parameters\n",
    "(thereby limiting the risk of overfitting). Reducing the input image size also makes\n",
    "the neural network tolerate a little bit of image shift (location invariance)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=conv1.png>\n",
    "<img src=conv2.png>\n",
    "<img src=conv3.png>\n",
    "<img src=conv5.png>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_iters = 200000\n",
    "batch_size = 150\n",
    "display_step = 10\n",
    "n_epochs = 5\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 784 # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "tf.reset_default_graph()\n",
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, n_input])\n",
    "y = tf.placeholder(tf.int64, [None])\n",
    "\n",
    "X=tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "conv1 = tf.layers.conv2d(\n",
    "      inputs=X,\n",
    "      filters=32,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "conv2 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=64,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "fc1 = tf.contrib.layers.fully_connected(inputs=pool2_flat, num_outputs=128, activation_fn=tf.nn.relu)\n",
    "logits=tf.contrib.layers.fully_connected(inputs=fc1, num_outputs=n_classes, activation_fn=None)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# # Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 1.0 Test accuracy: 0.986\n",
      "1 Train accuracy: 1.0 Test accuracy: 0.988\n",
      "2 Train accuracy: 1.0 Test accuracy: 0.986\n",
      "3 Train accuracy: 0.986667 Test accuracy: 0.991\n",
      "4 Train accuracy: 1.0 Test accuracy: 0.992\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(optimizer, feed_dict={x: X_batch, y: y_batch})\n",
    "            acc_train = accuracy.eval(feed_dict={x: X_batch, y: y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={x: mnist.test.images[:1000],y: mnist.test.labels[:1000]})\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
